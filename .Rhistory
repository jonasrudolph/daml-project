scale_fill_viridis(discrete = TRUE) +
labs(title = "Count of Races in Each Country",
x = "Country",
y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Erstellung des Boxplots für Expats und Einheimische
ggplot(filtered_data, aes(x = as.factor(Expat), y = Salary, fill = factor(Expat))) +
geom_boxplot() +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Vergleich der Gehälter von Zugewanderten und Einheimischen",
x = "Expat",
y = "Gehalt") +
scale_x_discrete(labels = c("Einheimische (0)", "Zugewanderte (1)")) +
theme_minimal()
# Mittelwert der Gehälter für Expats (Expat = 1)
mean_salary_expat <- mean(filtered_data$Salary[filtered_data$Expat == 1], na.rm = TRUE)
mean_salary_expat
# Mittelwert der Gehälter für Einheimische (Expat = 0)
mean_salary_native <- mean(filtered_data$Salary[filtered_data$Expat == 0], na.rm = TRUE)
mean_salary_native
# Bibliotheken laden
library(ggplot2)
library(dplyr)
# Daten berechnen
salary_percentiles <- filtered_data %>%
group_by(Education.Level) %>%
summarise(`10th Percentile` = quantile(Salary, probs = 0.1, na.rm = TRUE),
`25th Percentile` = quantile(Salary, probs = 0.25, na.rm = TRUE),
`50th Percentile (Median)` = quantile(Salary, probs = 0.5, na.rm = TRUE),
`75th Percentile` = quantile(Salary, probs = 0.75, na.rm = TRUE),
`90th Percentile` = quantile(Salary, probs = 0.9, na.rm = TRUE))
# Reshape der Daten für das Plotting
salary_percentiles_long <- salary_percentiles %>%
tidyr::pivot_longer(cols = -Education.Level, names_to = "Percentile", values_to = "Salary")
# Diagramm erstellen
ggplot(salary_percentiles_long, aes(x = Education.Level, y = Salary, fill = Percentile)) +
geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Perzentile des Gehalts nach Bildungsniveau",
x = "Bildungsniveau",
y = "Gehalt",
fill = "Perzentil") +
theme_minimal()
# Berechnung der Durchschnittsgehälter pro Bildungsniveau
average_salary_education <- aggregate(Salary ~ Education.Level, data = filtered_data, FUN = mean, na.rm = TRUE)
# Anzeige der Durchschnittsgehälter pro Bildungsniveau
average_salary_education
# Bildungsniveau nach aufsteigender Reihenfolge sortieren
filtered_data <- filtered_data %>%
mutate(Education.Level = factor(Education.Level, levels = unique(sort(Education.Level))))
# Boxplot erstellen
ggplot(filtered_data, aes(x = reorder(factor(Education.Level), Salary, FUN = median), y = Salary)) +
geom_boxplot(color = "black", fill = viridis(2)[2]) +
labs(title = "Boxplot des Gehalts nach Bildungsniveau",
x = "Bildungsniveau",
y = "Gehalt") +
theme_minimal()
# Bildungsniveau nach aufsteigender Reihenfolge sortieren
filtered_data <- filtered_data %>%
mutate(Education.Level = factor(Education.Level, levels = unique(sort(Education.Level))))
# Scatterplot erstellen
ggplot(filtered_data, aes(x = reorder(factor(Education.Level), Salary, FUN = median), y = Salary)) +
geom_point() +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Gehalt nach Bildungslevel",
x = "Bildungslevel",
y = "Gehalt") +
theme_minimal()
# Bildungslevel neu ordnen
filtered_data$Education.Level <- factor(filtered_data$Education.Level, levels = c("0", "1", "2", "3"))
# Liniendiagramm mit umgekehrter Reihenfolge des Bildungsniveaus erstellen
ggplot(filtered_data, aes(x = Education.Level, y = Salary, group = 1)) +
geom_line() +
stat_summary(fun.y = median, geom = "point", size = 3, color = "red") +
labs(title = "Gehalt nach Bildungslevel",
x = "Bildungslevel",
y = "Gehalt") +
theme_minimal()
# Kopie von filtered_data als filtered_data2 erstellen
filtered_data2 <- filtered_data
# Filtern der Daten für Jobs mit "Director" im Jobtitel in filtered_data2
director_jobs <- filtered_data2 %>%
filter(grepl("Director", Job.Title))
# Entfernen der Zeilen mit "Director" aus filtered_data2
filtered_data2 <- filtered_data2 %>%
anti_join(director_jobs)
nrow(director_jobs)
nrow(filtered_data)
nrow(filtered_data2)
# Filtern der Daten für technische und administrative Jobs basierend auf den Kriterien
technische_jobs <- subset(filtered_data, job_type == 0)
admin_jobs <- subset(filtered_data, job_type == 1)
# Durchschnittliche Gehälter pro Jobtyp für technische Jobs berechnen
average_salaries_technical <- mean(technische_jobs$Salary, na.rm = TRUE)
# Durchschnittliche Gehälter pro Jobtyp für administrative Jobs berechnen
average_salaries_admin <- mean(admin_jobs$Salary, na.rm = TRUE)
# Zusammenführen der durchschnittlichen Gehälter in einem Datenrahmen
all_average_salaries <- data.frame(Job.Type = c("technisch", "admin"),
Average.Salary = c(average_salaries_technical, average_salaries_admin))
# Erstellung des Diagramms mit angepasster Achsenbeschriftung
ggplot(all_average_salaries, aes(x = Job.Type, y = Average.Salary, fill = Job.Type)) +
geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Durchschnittliche Gehälter nach Jobtyp",
x = "Jobtyp",
y = "Durchschnittliches Gehalt") +
theme_minimal() +
scale_y_continuous(labels = scales::comma)  # Verwendung von scales::comma für die Achsenbeschriftung in Tausenden
# Filtern der Daten für technische und administrative Jobs basierend auf den Kriterien
technische_jobs <- subset(filtered_data, job_type == 0)
admin_jobs <- subset(filtered_data, job_type == 1)
# Durchschnittliche Gehälter pro Jobtyp für technische Jobs berechnen
average_salaries_technical <- mean(technische_jobs$Salary, na.rm = TRUE)
# Durchschnittliche Gehälter pro Jobtyp für administrative Jobs berechnen
average_salaries_admin <- mean(admin_jobs$Salary, na.rm = TRUE)
# Ausgabe der berechneten durchschnittlichen Gehälter mit Beschriftung
cat("Durchschnittliches Gehalt für technische Jobs:", average_salaries_technical, "\n")
cat("Durchschnittliches Gehalt für administrative Jobs:", average_salaries_admin, "\n")
#Daten nach Bildungsniveau, Land und Median des Gehalts gruppieren
summary_data <- aggregate(Salary ~ Education.Level + Country, data = filtered_data, FUN = median)
#Balkendiagramm erstellen
ggplot(summary_data, aes(x = Education.Level, y = Salary, fill = Country)) +
geom_bar(stat = "identity", position = "dodge") +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Median Gehalt nach Bildungslevel und Land",
x = "Bildungslevel",
y = "Median Gehalt",
fill = "Land") +
theme_minimal()
# Filtern der Daten für Jobs mit spezifischen Schlüsselwörtern im Jobtitel
filtered_data3 <- filtered_data %>%
filter(grepl("Data|Software|Developer|Engineer", Job.Title))
# Anzeigen aller eindeutigen Jobtitel und deren Häufigkeit in filtered_data3
job_title_count <- table(filtered_data3$Job.Title)
job_title_df <- data.frame(Job_Title = names(job_title_count), Frequency = as.numeric(job_title_count))
# Anzeige des Dataframes mit den Jobtiteln und deren Häufigkeit
job_title_df
# Filtern der Daten für Jobs ohne "Director" im Jobtitel
filtered_data3 <- filtered_data3 %>%
filter(!grepl("Director|Manager", Job.Title))
# Anzeigen aller eindeutigen Jobtitel und deren Häufigkeit in filtered_data3
job_title_count <- table(filtered_data3$Job.Title)
job_title_df <- data.frame(Job_Title = names(job_title_count), Frequency = as.numeric(job_title_count))
# Anzeige des Dataframes mit den Jobtiteln und deren Häufigkeit
job_title_df
# Erstellen der neuen Spalte 'data_job'
filtered_data3 <- filtered_data3 %>%
mutate(data_job = ifelse(grepl("Data", Job.Title), 1, 0))
# Zählen der Anzahl von 0 und 1 in der Spalte data_job
count_0 <- sum(filtered_data3$data_job == 0, na.rm = TRUE)
count_1 <- sum(filtered_data3$data_job == 1, na.rm = TRUE)
# Ausgabe der Anzahl von 0 und 1
cat("Anzahl der Zeilen mit dem Wert 0 bei data_job (Data Scientists & Engineers):", count_0, "\n")
cat("Anzahl der Zeilen mit dem Wert 1 bei data_job (Software Engineers & Co):", count_1, "\n")
# Berechnung der Quartile der Berufserfahrung
filtered_data4 <- filtered_data3 %>%
mutate(Experience_Quartile = ntile(Years.Of.Experience, 4))
# Balkendiagramm für data_job im Vergleich zum Gehalt
ggplot(filtered_data4, aes(x = factor(data_job), y = Salary)) +
stat_summary(fun = "mean", geom = "bar", position = "dodge", fill = viridis(2)[1]) +
labs(title = "Gehalt nach Data Job",
x = "Data Job",
y = "Gehalt (Mittelwert)")
# Erstellung des Balkendiagramms
ggplot(filtered_data4, aes(y = Salary, x = factor(Experience_Quartile))) +
geom_bar(stat = "identity", position = "dodge", aes(fill = factor(data_job))) +
labs(title = "Quartile der Berufserfahrung nach Gehalt und Jobtyp",
x = "Quartile der Berufserfahrung",
y = "Gehalt") +
theme_minimal() +
scale_fill_viridis(discrete = TRUE)
# Erstellung des Balkendiagramms für Education Level
ggplot(filtered_data4, aes(y = Salary, x = factor(Education.Level))) +
geom_bar(stat = "identity", position = "dodge", aes(fill = factor(data_job))) +
scale_fill_viridis(discrete = TRUE) +
labs(title = "Quartile des Bildungsniveaus nach Gehalt und Jobtyp",
x = "Quartile des Bildungsniveaus",
y = "Gehalt") +
theme_minimal()
# Erstelle eine neue Spalte "BIP_Per_Person" mit NA-Werten
filtered_data$BIP_Per_Person <- NA
# Weise den genannten Ländern die entsprechenden BIP-Werte zu
filtered_data$BIP_Per_Person[filtered_data$Country == "Australia"] <- 64813.85
filtered_data$BIP_Per_Person[filtered_data$Country == "Canada"] <- 53246.98
filtered_data$BIP_Per_Person[filtered_data$Country == "China"] <- 12541.40
filtered_data$BIP_Per_Person[filtered_data$Country == "UK"] <- 48912.78
filtered_data$BIP_Per_Person[filtered_data$Country == "USA"] <- 76343.00
head(filtered_data3)
# Scatterplot mit Farbgebung nach Ländern und Mittelwerten einzeichnen
ggplot(filtered_data, aes(x = BIP_Per_Person, y = Salary, color = Country)) +
geom_point() +
stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "black") +
labs(title = "Vergleich von Gehalt und BIP pro Person nach Ländern",
x = "BIP pro Person",
y = "Gehalt",
color = "Land") +
scale_color_viridis(discrete = TRUE)
# Berechnung der Mittelwerte nach Land
mean_salaries_by_country <- filtered_data3 %>%
group_by(Country) %>%
summarise(mean_salary = mean(Salary, na.rm = TRUE))
# Ausgabe der Mittelwerte nach Land
mean_salaries_by_country
# Berechnung der Mittelwerte nach Land
mean_salaries_by_country <- filtered_data %>%
group_by(Country) %>%
summarise(mean_salary = mean(Salary, na.rm = TRUE),
BIP_Per_Person = first(BIP_Per_Person))  # Annahme: BIP-Pro-Person-Werte sind konstant für jedes Land
# Ausgabe der Mittelwerte nach Land mit BIP pro Person
mean_salaries_by_country
cor(filtered_data$Salary, filtered_data$BIP_Per_Person, use = "complete.obs")
# Erstellen des neuen Datensatzes ohne Einträge für China
filtered_data_no_china <- filtered_data %>% filter(Country != "China")
cor(filtered_data_no_china$Salary, filtered_data_no_china$BIP_Per_Person, use = "complete.obs")
# Anzahl der Datensätze mit dem Land "China" im Datensatz filtered_data_no_china
count_china <- filtered_data_no_china %>% filter(Country == "China") %>% nrow()
count_china
filtered_data %>%
ggplot() +
aes(y = Salary, x = Years.Of.Experience) +
geom_point(aes(color = Salary), alpha = 0.8) +
geom_smooth(method = lm, color = "orange") +
scale_color_viridis(option = "D") +
scale_y_continuous(labels = scales::comma)
# Nur 'Salary' und 'Years.Of.Experience' behalten und den Rest entfernen
filtered_data5 <- filtered_data %>%
select(Salary, Years.Of.Experience)
# Z-Skalierung der Variable "Years.Of.Experience"
filtered_data5_z <- filtered_data5
filtered_data5_z$Years.Of.Experience <- scale(filtered_data5$Years.Of.Experience)
summary(filtered_data5_z)
sd(filtered_data5_z$Years.Of.Experience)
set.seed(007)
filtered_data5_z <- initial_split(filtered_data5_z, prop = 0.8, strata = Years.Of.Experience)
fd5_train <- training(filtered_data5_z)
fd5_test <- testing(filtered_data5_z)
# Modell initialisieren
lm_model <- linear_reg() |> set_engine("lm")
# Lineare Regression von "Salary" basierend auf "Years.Of.Experience"
lm_fit <- lm_model |> fit(Salary ~ Years.Of.Experience, data = fd5_train)
# Zusammenfassung der Regression
summary <- lm_fit |> extract_fit_engine() |> summary()
summary
pred_train <- predict(lm_fit, new_data = fd5_train) |> rename("pred_train" = ".pred")
pred_test <- predict(lm_fit, new_data = fd5_test) |>  rename("pred_test" = ".pred")
compare_train <- fd5_train |>
select(Salary) |>
bind_cols(pred_train)
head(compare_train)
compare_test <- fd5_test |>
select(Salary) |>
bind_cols(pred_test)
head(compare_test)
# Daten für Training und Test
train_data <- cbind(fd5_train, pred_train)
test_data <- cbind(fd5_test, pred_test)
# Erstellen Sie eine ggplot-Grafik für die Trainingsdaten
ggplot(train_data, aes(x = Years.Of.Experience, y = Salary)) +
geom_point(color = viridis(0.50), alpha = 0.5) +
geom_line(aes(y = pred_train), color = "deeppink3", size = 1) +
labs(title = "Vorhersage auf Trainingsdaten",
x = "Years of Experience",
y = "Salary") +
scale_color_identity() +  # Farben beibehalten
scale_y_continuous(labels = scales::comma) +
theme_minimal()
# Erstellen Sie eine ggplot-Grafik für die Testdaten
ggplot(test_data, aes(x = Years.Of.Experience, y = Salary)) +
geom_point(color = viridis(0.50), alpha = 0.5) +
geom_line(aes(y = pred_test), color = "deeppink3", size = 1) +
labs(title = "Vorhersage auf Testdaten",
x = "Years of Experience",
y = "Salary") +
scale_color_identity() +  # Farben beibehalten
scale_y_continuous(labels = scales::comma) +
theme_minimal()
rmse(compare_train, Salary, pred_train)
rmse(compare_test, Salary, pred_test)
describe(filtered_data5, Salary)
describe(filtered_data5, Years.Of.Experience)
# Residuen mit augment() auf den Trainingsdaten abrufen
residuals_train <- augment(lm_fit, new_data = fd5_train) %>% select(.resid)
# Residuen mit augment() auf den Testdaten abrufen
residuals_test <- augment(lm_fit, new_data = fd5_test) %>% select(.resid)
# Ausgabe der Residuen für Trainingsdaten
print(residuals_train)
# Ausgabe der Residuen für Testdaten
print(residuals_test)
# Standardisierung/Z-Skalierung der Residuen der Residuen
residuals_train$standardized_resid <- scale(residuals_train$.resid)
# Histogramm der standardisierten Residuen mit Viridis-Farbschema
ggplot(data = residuals_train, aes(x = standardized_resid)) +
geom_histogram(binwidth = 0.5, fill = viridis(1), color = "black", alpha = 0.7) +
labs(title = "Histogramm der standardisierten Residuen",
x = "Standardisierte Residuen",
y = "Häufigkeit") +
scale_fill_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
# Standardisierung/Z-Skalierung der Residuen der Residuen
residuals_test$standardized_resid <- scale(residuals_test$.resid)
# Histogramm der standardisierten Residuen mit Viridis-Farbschema
ggplot(data = residuals_test, aes(x = standardized_resid)) +
geom_histogram(binwidth = 0.5, fill = viridis(1), color = "black", alpha = 0.7) +
labs(title = "Histogramm der standardisierten Residuen",
x = "Standardisierte Residuen",
y = "Häufigkeit") +
scale_fill_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
# QQ-Plot erstellen
ggplot(data = residuals_train, aes(sample = standardized_resid)) +
stat_qq(distribution = qnorm, dparams = list(mean = 0, sd = 1), color = viridis(1)) +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
labs(title = "QQ-Plot der standardisierten Residuen",
x = "Quantile der Normalverteilung",
y = "Quantile der Residuen") +
scale_color_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
residuals_test$standardized_resid <- scale(residuals_test$.resid)
# QQ-Plot erstellen
ggplot(data = residuals_test, aes(sample = standardized_resid)) +
stat_qq(distribution = qnorm, dparams = list(mean = 0, sd = 1), color = viridis(1)) +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
labs(title = "QQ-Plot der standardisierten Residuen",
x = "Quantile der Normalverteilung",
y = "Quantile der Residuen") +
scale_color_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
# Annahme: Sie haben ein DataFrame namens filtered_data3
# Führen Sie die lineare Regression durch
linear_model <- lm(Salary ~ Years.Of.Experience, data = filtered_data3)
# Berechnen Sie den Adjusted R-squared-Wert
adjusted_r_squared <- summary(linear_model)$adj.r.squared
# Drucken Sie den Adjusted R-squared-Wert
cat("Adjusted R-squared:", adjusted_r_squared, "\n")
# Beispiel für ein Streudiagramm und eine glättende Funktion
library(ggplot2)
ggplot(data = filtered_data, aes(x = Years.Of.Experience, y = Salary)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE)
# Beispiel für ein Streudiagramm und eine glättende Funktion
library(ggplot2)
ggplot(data = filtered_data, aes(x = Years.Of.Experience, y = Salary)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE)
# Beispiel für ein Streudiagramm und eine glättende Funktion
library(ggplot2)
ggplot(data = filtered_data, aes(x = Years.Of.Experience, y = Salary)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE)
filtered_data$Education.Level <- as.numeric(as.character(filtered_data$Education.Level))
str(filtered_data$Education.Level)
# Berechnen Sie die Korrelationen
correlations <- cor(filtered_data[c("Salary", "Age", "Years.Of.Experience", "Education.Level")])
# Drucken Sie die Korrelationen
print(correlations)
filtered_data6 <- filtered_data %>%
select(Salary, Years.Of.Experience, Education.Level)
# Fügen Sie die zusätzliche Spalte mit dem quadrierten Wert hinzu
filtered_data6 <- filtered_data6 %>%
mutate(Years.Of.Experience_Squared = Years.Of.Experience^2) %>%
mutate(Years.Of.Experience_Cubed = Years.Of.Experience^3) %>%
mutate(Years.Of.Experience_Quartic = Years.Of.Experience^4)
head(filtered_data6)
# Erstellen Sie eine Kopie von filtered_data6
filtered_data6_z <- filtered_data6
# Z-Skalierung für Years.Of.Experience und Education.Level in filtered_data6_z durchführen
filtered_data6_z <- filtered_data6_z %>%
mutate(
Years.Of.Experience = scale(Years.Of.Experience),
Education.Level = scale(Education.Level)
)
head(filtered_data6_z)
sd(filtered_data6_z$Years.Of.Experience)
sd(filtered_data6_z$Education.Level)
set.seed(007)
filtered_data6_z <- initial_split(filtered_data6_z, prop = 0.8, strata = Years.Of.Experience)
fd6_train <- training(filtered_data6_z)
fd6_test <- testing(filtered_data6_z)
# Modell initialisieren
lm_model2 <- linear_reg() |> set_engine("lm")
# Lineare Regression von "Salary" basierend auf "Years.Of.Experience"
lm_fit2 <- lm_model2 |> fit(Salary ~ Years.Of.Experience + Education.Level + Years.Of.Experience_Squared, data = fd6_train)
lm_fit3 <- lm_model2 |> fit(Salary ~ Years.Of.Experience + Education.Level + Years.Of.Experience_Cubed, data = fd6_train)
lm_fit4 <- lm_model2 |> fit(Salary ~ Years.Of.Experience + Education.Level + Years.Of.Experience_Quartic, data = fd6_train)
# Zusammenfassung der Regression
summary <- lm_fit2 |> extract_fit_engine() |> summary()
summary
# Zusammenfassung der Regression
summary <- lm_fit3 |> extract_fit_engine() |> summary()
summary
# Zusammenfassung der Regression
summary <- lm_fit4 |> extract_fit_engine() |> summary()
summary
pred_train2 <- predict(lm_fit2, new_data = fd6_train) |> rename("pred_train2" = ".pred")
pred_test2 <- predict(lm_fit2, new_data = fd6_test) |>  rename("pred_test2" = ".pred")
compare_train2 <- fd5_train |>
select(Salary) |>
bind_cols(pred_train2)
head(compare_train2)
compare_test2 <- fd5_test |>
select(Salary) |>
bind_cols(pred_test2)
head(compare_test2)
pred_train3 <- predict(lm_fit3, new_data = fd6_train) |> rename("pred_train3" = ".pred")
pred_test3 <- predict(lm_fit3, new_data = fd6_test) |>  rename("pred_test3" = ".pred")
compare_train3 <- fd6_train |>
select(Salary) |>
bind_cols(pred_train3)
head(compare_train3)
compare_test3 <- fd6_test |>
select(Salary) |>
bind_cols(pred_test3)
head(compare_test3)
pred_train4 <- predict(lm_fit4, new_data = fd6_train) |> rename("pred_train4" = ".pred")
pred_test4 <- predict(lm_fit4, new_data = fd6_test) |>  rename("pred_test4" = ".pred")
compare_train4 <- fd6_train |>
select(Salary) |>
bind_cols(pred_train4)
head(compare_train4)
compare_test4 <- fd6_test |>
select(Salary) |>
bind_cols(pred_test4)
head(compare_test4)
# Erstellen des Vorhersage-Plots für den Trainingsdatensatz
ggplot(compare_train2, aes(x = Salary, y = pred_train2)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
labs(title = "Vorhersage-Plot für Trainingsdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
# Erstellen des Vorhersage-Plots für den Testdatensatz
ggplot(compare_test2, aes(x = Salary, y = pred_test2)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE) +
labs(title = "Vorhersage-Plot für Testdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
# Erstellen des Vorhersage-Plots für den Trainingsdatensatz
ggplot(compare_train3, aes(x = Salary, y = pred_train3)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
labs(title = "Vorhersage-Plot für Trainingsdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
# Erstellen des Vorhersage-Plots für den Testdatensatz
ggplot(compare_test3, aes(x = Salary, y = pred_test3)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
labs(title = "Vorhersage-Plot für Testdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
# Erstellen des Vorhersage-Plots für den Trainingsdatensatz
ggplot(compare_train4, aes(x = Salary, y = pred_train4)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
labs(title = "Vorhersage-Plot für Trainingsdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
# Erstellen des Vorhersage-Plots für den Testdatensatz
ggplot(compare_test4, aes(x = Salary, y = pred_test4)) +
geom_point(color = viridis(0.50)) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE) +
labs(title = "Vorhersage-Plot für Testdatensatz",
x = "Echte Salary-Werte",
y = "Vorhergesagte Salary-Werte") +
theme_minimal()
rmse(compare_train2, Salary, pred_train2)
rmse(compare_test2, Salary, pred_test2)
rmse(compare_train3, Salary, pred_train3)
rmse(compare_test3, Salary, pred_test3)
rmse(compare_test4, Salary, pred_test4)
rmse(compare_test4, Salary, pred_test4)
describe(filtered_data5, Salary)
# Residuen mit augment() auf den Trainingsdaten abrufen
residuals_train2 <- augment(lm_fit4, new_data = fd6_train) %>% select(.resid)
# Residuen mit augment() auf den Testdaten abrufen
residuals_test2 <- augment(lm_fit4, new_data = fd6_test) %>% select(.resid)
# Ausgabe der Residuen für Trainingsdaten
print(residuals_train2)
# Ausgabe der Residuen für Testdaten
print(residuals_test2)
# Standardisierung/Z-Skalierung der Residuen der Residuen
residuals_train2$standardized_resid2 <- scale(residuals_train2$.resid)
# Histogramm der standardisierten Residuen mit Viridis-Farbschema
ggplot(data = residuals_train2, aes(x = standardized_resid2)) +
geom_histogram(binwidth = 0.5, fill = viridis(1), color = "black", alpha = 0.7) +
labs(title = "Histogramm der standardisierten Residuen",
x = "Standardisierte Residuen",
y = "Häufigkeit") +
scale_fill_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
# Standardisierung/Z-Skalierung der Residuen der Residuen
residuals_test2$standardized_resid2 <- scale(residuals_test2$.resid)
# Histogramm der standardisierten Residuen mit Viridis-Farbschema
ggplot(data = residuals_test2, aes(x = standardized_resid2)) +
geom_histogram(binwidth = 0.5, fill = viridis(1), color = "black", alpha = 0.7) +
labs(title = "Histogramm der standardisierten Residuen",
x = "Standardisierte Residuen",
y = "Häufigkeit") +
scale_fill_viridis() +  # Fügt das Viridis-Farbschema hinzu
theme_minimal()
